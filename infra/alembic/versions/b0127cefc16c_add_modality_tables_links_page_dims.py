"""add modality tables, links, page dims

Revision ID: b0127cefc16c
Revises: 1e4879a5c508
Create Date: 2025-11-02 14:33:05.851912

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy  # for VECTOR(dim=...)

# revision identifiers, used by Alembic.
revision: str = 'b0127cefc16c'
down_revision: Union[str, Sequence[str], None] = '1e4879a5c508'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('links',
    sa.Column('link_id', sa.UUID(), nullable=False),
    sa.Column('src_segment_id', sa.UUID(), nullable=False),
    sa.Column('src_modality', sa.String(), nullable=False),
    sa.Column('dst_segment_id', sa.UUID(), nullable=False),
    sa.Column('dst_modality', sa.String(), nullable=False),
    sa.Column('relation', sa.String(), nullable=False),
    sa.Column('scope', sa.String(), nullable=False),
    sa.Column('scope_id', sa.UUID(), nullable=True),
    sa.Column('weight', sa.Float(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('created_by', sa.Text(), nullable=True),
    sa.Column('method', sa.Text(), nullable=True),
    sa.Column('model_version', sa.Text(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('link_id')
    )
    op.create_index('idx_links_dst', 'links', ['dst_segment_id'], unique=False)
    op.create_index('idx_links_scope', 'links', ['scope', 'scope_id'], unique=False)
    op.create_index('idx_links_src', 'links', ['src_segment_id'], unique=False)
    # drop duplicate implicit indexes; keep explicit idx_links_* only
    op.create_table('bibliography_entries',
    sa.Column('bib_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('label', sa.Text(), nullable=True),
    sa.Column('raw_text', sa.Text(), nullable=False),
    sa.Column('parsed', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('bib_id')
    )
    op.create_index(op.f('ix_bibliography_entries_doc_id'), 'bibliography_entries', ['doc_id'], unique=False)
    op.create_table('link_anchors',
    sa.Column('link_id', sa.UUID(), nullable=False),
    sa.Column('atype', sa.String(), nullable=False),
    sa.Column('anchor', sa.JSON(), nullable=False),
    sa.ForeignKeyConstraint(['link_id'], ['links.link_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('link_id', 'atype')
    )
    op.create_table('table_sets',
    sa.Column('table_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.Text(), nullable=True),
    sa.Column('n_rows', sa.Integer(), nullable=True),
    sa.Column('n_cols', sa.Integer(), nullable=True),
    sa.Column('schema', sa.JSON(), nullable=True),
    sa.Column('page_no', sa.Integer(), nullable=True),
    sa.Column('bbox', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('table_id')
    )
    op.create_index(op.f('ix_table_sets_doc_id'), 'table_sets', ['doc_id'], unique=False)
    op.create_table('video_segments',
    sa.Column('segment_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('shot_id', sa.Text(), nullable=True),
    sa.Column('frame_idx', sa.Integer(), nullable=True),
    sa.Column('t0_ms', sa.Integer(), nullable=True),
    sa.Column('t1_ms', sa.Integer(), nullable=True),
    sa.Column('keyframe_uri', sa.Text(), nullable=True),
    sa.Column('emb_v1', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True),
    sa.Column('emb_model', sa.Text(), nullable=True),
    sa.Column('emb_version', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('segment_id')
    )
    op.create_index('idx_video_segments_doc', 'video_segments', ['doc_id'], unique=False)
    op.create_index('idx_video_segments_emb_v1', 'video_segments', ['emb_v1'], unique=False, postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.create_index(op.f('ix_video_segments_doc_id'), 'video_segments', ['doc_id'], unique=False)
    op.create_table('audio_segments',
    sa.Column('segment_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('t0_ms', sa.Integer(), nullable=False),
    sa.Column('t1_ms', sa.Integer(), nullable=False),
    sa.Column('transcript_chunk_id', sa.UUID(), nullable=True),
    sa.Column('emb_v1', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True),
    sa.Column('emb_model', sa.Text(), nullable=True),
    sa.Column('emb_version', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['transcript_chunk_id'], ['chunks.chunk_id'], ),
    sa.PrimaryKeyConstraint('segment_id')
    )
    op.create_index('idx_audio_segments_doc', 'audio_segments', ['doc_id'], unique=False)
    op.create_index('idx_audio_segments_emb_v1', 'audio_segments', ['emb_v1'], unique=False, postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.create_index(op.f('ix_audio_segments_doc_id'), 'audio_segments', ['doc_id'], unique=False)
    op.create_table('citation_anchors',
    sa.Column('anchor_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('page_no', sa.Integer(), nullable=False),
    sa.Column('char_offset', sa.Integer(), nullable=True),
    sa.Column('marker', sa.String(), nullable=False),
    sa.Column('target_bib', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['target_bib'], ['bibliography_entries.bib_id'], ),
    sa.PrimaryKeyConstraint('anchor_id')
    )
    op.create_index('idx_citation_anchors_doc_page', 'citation_anchors', ['doc_id', 'page_no'], unique=False)
    op.create_index(op.f('ix_citation_anchors_doc_id'), 'citation_anchors', ['doc_id'], unique=False)
    op.create_table('figures',
    sa.Column('figure_id', sa.UUID(), nullable=False),
    sa.Column('doc_id', sa.UUID(), nullable=False),
    sa.Column('page_no', sa.Integer(), nullable=False),
    sa.Column('bbox', sa.JSON(), nullable=True),
    sa.Column('caption_chunk_id', sa.UUID(), nullable=True),
    sa.Column('image_uri', sa.Text(), nullable=True),
    sa.Column('emb_v1', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True),
    sa.Column('emb_model', sa.Text(), nullable=True),
    sa.Column('emb_version', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['caption_chunk_id'], ['chunks.chunk_id'], ),
    sa.ForeignKeyConstraint(['doc_id'], ['documents.doc_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('figure_id')
    )
    op.create_index('idx_figures_doc_page', 'figures', ['doc_id', 'page_no'], unique=False)
    op.create_index('idx_figures_emb_v1', 'figures', ['emb_v1'], unique=False, postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.create_index(op.f('ix_figures_doc_id'), 'figures', ['doc_id'], unique=False)
    op.create_table('table_rows',
    sa.Column('row_id', sa.UUID(), nullable=False),
    sa.Column('table_id', sa.UUID(), nullable=False),
    sa.Column('row_index', sa.Integer(), nullable=False),
    sa.Column('row_json', sa.JSON(), nullable=False),
    sa.Column('row_text', sa.Text(), nullable=False),
    sa.Column('row_text_fts', postgresql.TSVECTOR(), nullable=False),
    sa.Column('emb_v1', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True),
    sa.Column('emb_model', sa.Text(), nullable=True),
    sa.Column('emb_version', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['table_id'], ['table_sets.table_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('row_id')
    )
    op.create_index('idx_table_rows_emb_v1', 'table_rows', ['emb_v1'], unique=False, postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.create_index('idx_table_rows_fts', 'table_rows', ['row_text_fts'], unique=False, postgresql_using='gin')
    op.create_index('idx_table_rows_table_idx', 'table_rows', ['table_id', 'row_index'], unique=False)
    op.create_index(op.f('ix_table_rows_table_id'), 'table_rows', ['table_id'], unique=False)
    # Maintain table_rows.row_text_fts via trigger (mirror chunks trigger style)
    op.execute(
        """
        CREATE FUNCTION table_rows_fts_trigger() RETURNS trigger LANGUAGE plpgsql AS $$
        BEGIN
          NEW.row_text_fts := to_tsvector('simple'::regconfig, unaccent(coalesce(NEW.row_text,'')));
          RETURN NEW;
        END$$;
        """
    )
    op.execute(
        """
        CREATE TRIGGER trg_table_rows_fts BEFORE INSERT OR UPDATE ON table_rows
        FOR EACH ROW EXECUTE FUNCTION table_rows_fts_trigger();
        """
    )
    op.add_column('pages', sa.Column('width_px', sa.Integer(), nullable=True))
    op.add_column('pages', sa.Column('height_px', sa.Integer(), nullable=True))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('pages', 'height_px')
    op.drop_column('pages', 'width_px')
    op.drop_index(op.f('ix_table_rows_table_id'), table_name='table_rows')
    op.drop_index('idx_table_rows_table_idx', table_name='table_rows')
    op.drop_index('idx_table_rows_fts', table_name='table_rows', postgresql_using='gin')
    op.drop_index('idx_table_rows_emb_v1', table_name='table_rows', postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.execute("DROP TRIGGER IF EXISTS trg_table_rows_fts ON table_rows")
    op.execute("DROP FUNCTION IF EXISTS table_rows_fts_trigger()")
    op.drop_table('table_rows')
    op.drop_index(op.f('ix_figures_doc_id'), table_name='figures')
    op.drop_index('idx_figures_emb_v1', table_name='figures', postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.drop_index('idx_figures_doc_page', table_name='figures')
    op.drop_table('figures')
    op.drop_index(op.f('ix_citation_anchors_doc_id'), table_name='citation_anchors')
    op.drop_index('idx_citation_anchors_doc_page', table_name='citation_anchors')
    op.drop_table('citation_anchors')
    op.drop_index(op.f('ix_audio_segments_doc_id'), table_name='audio_segments')
    op.drop_index('idx_audio_segments_emb_v1', table_name='audio_segments', postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.drop_index('idx_audio_segments_doc', table_name='audio_segments')
    op.drop_table('audio_segments')
    op.drop_index(op.f('ix_video_segments_doc_id'), table_name='video_segments')
    op.drop_index('idx_video_segments_emb_v1', table_name='video_segments', postgresql_using='hnsw', postgresql_ops={'emb_v1': 'vector_cosine_ops'})
    op.drop_index('idx_video_segments_doc', table_name='video_segments')
    op.drop_table('video_segments')
    op.drop_index(op.f('ix_table_sets_doc_id'), table_name='table_sets')
    op.drop_table('table_sets')
    op.drop_table('link_anchors')
    op.drop_index(op.f('ix_bibliography_entries_doc_id'), table_name='bibliography_entries')
    op.drop_table('bibliography_entries')
    # removed drops for implicit ix_links_* indexes (not created)
    op.drop_index('idx_links_src', table_name='links')
    op.drop_index('idx_links_scope', table_name='links')
    op.drop_index('idx_links_dst', table_name='links')
    op.drop_table('links')
    # ### end Alembic commands ###
